{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "025f98ea",
   "metadata": {},
   "source": [
    "Amazon Simple Storage Service (Amazon S3) is object storage commonly used for data analytics applications, machine learning, websites, and many more"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebae4d1",
   "metadata": {},
   "source": [
    "Boto3 is the Python SDK for Amazon Web Services (AWS) that allows you to manage AWS services in a programmatic way from your applications and services."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3a2a00",
   "metadata": {},
   "source": [
    "Using the Boto3 library with Amazon Simple Storage Service (S3) allows you to create, update, and delete S3 Buckets, Objects, S3 Bucket Policies, and many more from Python programs or scripts with ease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14d66e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Downloading boto3-1.24.36-py3-none-any.whl (132 kB)\n",
      "Collecting botocore<1.28.0,>=1.27.36\n",
      "  Downloading botocore-1.27.36-py3-none-any.whl (9.0 MB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting s3transfer<0.7.0,>=0.6.0\n",
      "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\nithya\\anaconda3\\lib\\site-packages (from botocore<1.28.0,>=1.27.36->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\nithya\\anaconda3\\lib\\site-packages (from botocore<1.28.0,>=1.27.36->boto3) (1.26.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nithya\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.36->boto3) (1.16.0)\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.24.36 botocore-1.27.36 jmespath-1.0.1 s3transfer-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb70f12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading to Amazon S3 bucket\n",
      "..........Uploading to Amazon S3 bucket\n"
     ]
    }
   ],
   "source": [
    "#Create s3 bucket and push the target file to the same s3 bucket  \n",
    "import boto\n",
    "import boto.s3\n",
    "import sys\n",
    "from boto.s3.key import Key\n",
    "\n",
    "AWS_ACCESS_KEY_ID ='AKIAZEBLVBXAWBSWX44H'\n",
    "\n",
    "#Type in AWS IAM  Access Key\n",
    "AWS_SECRET_ACCESS_KEY ='dmpCVCed86GL9XanRF65kKU9I+W4o7r7jrlh9c+5'                                \n",
    "# type in AWS IAM Secret Access Key \n",
    "\n",
    "bucket_name ='ddemo4'# Name of the Bucket to be created. \n",
    "conn = boto.connect_s3(AWS_ACCESS_KEY_ID,AWS_SECRET_ACCESS_KEY)\n",
    "\n",
    "from boto.s3.connection import Location\n",
    "#print ('\\n'.join(i for i in dir(Location) if i[0].isupper()))\n",
    "#conn.create_bucket('mybucket', location=Location.EU)\n",
    "bucket = conn.create_bucket(bucket_name,location=boto.s3.connection.Location.DEFAULT)\n",
    "\n",
    "testfile1 = \"D://Files//.csv\" #Your .csv File location  \n",
    "\n",
    "print ('Uploaded to Amazon S3 bucket')\n",
    "\n",
    "def percent_cb(complete, total):\n",
    "    sys.stdout.write('.')\n",
    "    sys.stdout.flush() #flush() pushes out all the data that has been buffered to that point to a file\n",
    "    #object ,While using stdout, data is stored in buffer memory\n",
    "\n",
    "\n",
    "k = Key(bucket)\n",
    "k.key = 'mmix.csv' #Naming of the file after pushing to s3 bucket  \n",
    "k.set_contents_from_filename(testfile1, cb=percent_cb, num_cb=10)\n",
    "print('Uploaded to Amazon S3 bucket')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "574ee27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#delete the content inside s3 bucket and then  deletes s3 bucket \n",
    "import boto\n",
    "from boto.s3.key import Key\n",
    "import boto.s3.connection\n",
    "from __future__ import print_function\n",
    "\n",
    "ACCESS_KEY_ID ='AKIAZEBLVBXAWBSWX44H'\n",
    "SECRET_ACCESS_KEY ='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'\n",
    "\n",
    "conn = boto.s3.connect_to_region('us-east-1',\n",
    "                                 aws_access_key_id=ACCESS_KEY_ID, aws_secret_access_key=SECRET_ACCESS_KEY)\n",
    "\n",
    "ls =list(map(lambda bucket: bucket.name, conn.get_all_buckets())) #getting the list of bucketnames\n",
    "print(ls)\n",
    "for i in ls:\n",
    "    print(i)\n",
    "    db = conn.get_bucket(i)\n",
    "    for key in db.list():\n",
    "        key.delete()  # deleting the contents inside s3 bucket \n",
    "        conn.delete_bucket(i)\n",
    "        print(i+' bucket deleted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada92ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
